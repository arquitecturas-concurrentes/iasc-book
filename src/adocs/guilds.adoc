= Guild wars (?)

Como vimos en las clases anteriores, Ruby MRI posee "algunos problemas" en cuanto a como maneja el procesamiento en paralelo en múltiples procesadores. Si bien vimos que la concurrencia es algo que perfectamente puede darse sin necesidad de contextos de ejecución que se ejecuten al mismo tiempofootnote:1[https://arquitecturas-concurrentes.github.io/iasc-book/concurrencia_paralelismo[IASC UTN FRBA. (2020) .Concurrencia y Paralelismo\]], vamos a ver en esta sección, nuevos y existentes mecanismos para tratar de resolver este problema latente en MRI desde sus comienzos.

[.center.iasc-image]
image:/public/img/guilds/pisa_tower.jpeg[]

[discrete]
=== Un poco de historia...

Ruby puede implementar mecanismos concurrentes pero no paralelos debido al GVL a.k.a GIL (Global VM Lock o Giant VM Lock), que es un bloqueo de exclusión mutua, en suma, un mutex. Este bloqueo lo mantiene el subproceso del intérprete y lo usa para evitar compartir código que no es seguro para subprocesos con otros subprocesos. Todos los hilos de intérpretes tienen su propio GIL. Debido a dicho GIL, si un programa Ruby tiene múltiples hilos, no pueden ejecutarse al mismo tiempo, porque GIL solo permitirá que se ejecute un subproceso al mismo tiempo. Antes de Ruby 1.9, solo había un hilo del sistema operativo para todos los hilos de sistema de MRI que podemos crear mediante la librería standard de Rubyfootnote:2[https://ruby-doc.org/core-3.0.2/Thread.html[Ruby Doc. Retrieved 30 August 2021. Thread standard library\]].

[.center.iasc-image]
image::/public/img/guilds/xruby-gil-jvm.png[]

::: warning
_Extra_: El mecanismo de como se adquiere y libera el GVL se puede ver https://github.com/ruby/ruby/blob/a8714b83c40c8736b4ddafef08fa5f0091c9b101/thread_pthread.c#L314[aqui] y https://github.com/ruby/ruby/blob/a8714b83c40c8736b4ddafef08fa5f0091c9b101/thread_pthread.c#L236[aqui] se puede ver la lógica del timeslice donde se ejecuta el thread que pudo adquirir el GVL.
:::

Como vemos en la foto, después de Ruby 1.9, podemos tener varios hilos del sistema operativo y estos se relacionan 1:1 contra nuestros hilos de usuario, pero debido al GVL, como se menciono antes, _solo y solo un hilo_, de todos los hilos del sistema operativo creados pueden ejecutarse al mismo tiempo, descartando la posibilidad de soporte SMP.

[.center.iasc-image]
image::/public/img/guilds/in_rod_we_trust.png[]

La inerte barra de carbono representa el GVL siendo tomado por un hilo..

Este tipo de mecanismos son algo visto no solo en MRI sino también en CPythonfootnote:3[https://wiki.python.org/moin/GlobalInterpreterLock[Python Moin. Retrieved 30 November 2015. GlobalInterpreterLock\]], y ambas máquinas virtuales sufren de los mismos problemas.

En Java también se puede definir múltiples subprocesos,pero la diferencia es que en la JVM,se puede mapear cada hilo de la JVM a uno del sistema operativo. Esto permite aprovechar la arquitectura multinúcleo. En este caso cuando usamos JRuby, la librería de `threads` de Ruby, es en realidad un wrapper de los hilos de la JVM, por esta razón, vamos a poder tener exactamente el mismo código y vamos a poder tener soporte SMP.

[discrete]
=== Status Quo: Workers

Una manera de poder aprovechar la ejecución de múltiples procesadores, es algo que vimos en Pumafootnote:5[https://puma.io/puma/file.architecture.html[Puma Doc. Architecture Overview\]], es que se pueda trabajar como si fuese un `'cluster'`, en donde el proceso principal inicializa la aplicación, y luego se usa el syscall https://man7.org/linux/man-pages/man2/fork.2.html[`fork()`] para crear 1 o más procesos hijos. Estos procesos hijos, en el caso de Puma por ejemplo, escuchan al mismo socket que el proceso padre, y este último deja de escuchar al socket, para solo ser relegado para escuchar a señales de UNIX y posiblemente para matar/iniciar los procesos hijos.

[.center.iasc-image]
image::/public/img/guilds/puma-general-arch.png[]

Este mecanismo, si bien es simple, puede dar la sensación de que si bien empieza cada proceso hijo, con poca memoria, gradualmente ira creciendo hasta ser tan grande como el proceso padre. Incluso en grandes entornos de producción, esto puede significar una gran cantidad de memoria, y crear un problema de falta de memoria si tenemos muchos _workers/procesos hijos_.

Sin embargo, los sistemas operativos modernos, tienen manejo de memoria virtual, que proveen de un mecanismo llamado _copy on write_footnote:4[http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=C97A7B66D788B7E4F6D6BF5FDD8EC451?doi=10.1.1.33.3144&rep=rep1&type=pdf[Javier, Francisco & Guttman, Joshua. (1995). Copy on Write.\]], que previene del escenario que describimos antes. La memoria virtual de un proceso, esta separado en bloques de 4k, llamadas paginas. Cuando un proceso padre, crea un proceso hijo; el hijo inicialmente comparte todas las paginas de memoria con el padre. Solo cuando el proceso hijo empieza a modificar una o varias de estas paginas, el kernel se encargara de copiar las paginas de memoria modificadas, y de reasignarlo al nuevo proceso.

[.center.iasc-image]
image::/public/img/guilds/child-processes.svg[]

El diagrama visto más arriba, muestra un poco como van cambiando, y copiandose las paginas a medida que pasa el tiempo. El mecanismo de como MRI aloca memoria puede verse muy bien explicado enfootnote:6[https://brandur.org/ruby-memory[Brandur. (2017). The Limits of Copy-on-write: How Ruby Allocates Memory\]].

[discrete]
=== La propuesta: Guilds

Si bien tener múltiples procesos hijos permite de alguna manera saltear y poder aprovechar más procesadores, existen varias desventajas por lo que no es a veces una solución óptima.

Una de ellas es que tengamos que realizar un offloading que no tengo demasiado estado, y por consiguiente, tengamos contextos de ejecución algo "pesados", y que consume más memoria de lo que realmente necesita o se justifica. En caso de que tengamos que trabajar con algún tipo de hardware que no posee tantos recursos, por ejemplo hardware embebido, tal vez necesitemos hacer un mejor uso de la memoria existente, con lo cual tener múltiples procesos puede llegar a ser muy costoso. Otra razón es que el uso de un `fork()`, implica que hay que recurrir a una solución, que esta por afuera en parte de las abstracciones que maneja o soporta MRI.

Estas razones, hicieron que en parte se busque por una solución parcial o definitiva, sin tener que recurrir a algo tan extremo, como el de eliminar por completo el GVL, debido a que se necesiten realizar cambios muchos más drásticos, a nivel de manejo de memoria y GC.

El origen de Ractor se remonta a 2016 cuando Koichi Sasada (diseñador de la máquina virtual Ruby y recolección de basura) presentó su propuesta sobre un nuevo modelo de concurrencia para Ruby. Antes de dicha propuesta, solo podíamos aprovechar múltiples procesadores mediante subprocesos hijos.

En 2016, Koichi habló sobre los problemas de la programación de subprocesos múltiples en su presentación en Ruby Kaigifootnote:7[http://www.atdot.net/~ko1/activities/2016_rubykaigi.pdf[Sasada, Koichi. (2016). A proposal of new concurrency model for Ruby 3 (RubyKaigi2016)\]], así como sobre algunas formas comunes de resolverlos. Junto con eso, también presentó su concepto de `Guilds` por primera vez. Antes de pasar a Ractors, tomemos un momento para comprender los aspectos básicos de Ractors: `Guilds`.

[discrete]
==== Que es un Guild?

::: warning
Las imágenes a continuación fueron tomadas de la presentación de Koichi Sasadafootnote:7[]
:::

Un Guild, fue propuesto, como una una nueva abstracción de concurrencia para Ruby. Donde cada uno de estos `Guilds`, tendría uno o más hilos, y cada uno de estos, a su vez, albergaría una o más "fibers"/corutinas.

[.center.iasc-image]
image::/public/img/guilds/guilds_0.png[]

Los hijos de dos `Guilds`, podrían ejecutarse en paralelo, pero los hijos que estan enmarcados dentro de un mismo `Guild` no. Esto se garantizaría a través de un nuevo lock llamado GGL, que solo permite ejecutar en primer plano a un hilo a la vez.

[.center.iasc-image]
image::/public/img/guilds/guilds_1.png[]

Además, todos los Guilds tendrían su propio conjunto de objetos mutables, y un `Guild` no podría modificar los objetos de otro `Guild`. Esto se propuso para evitar problemas de inconsistencia de datos debido al acceso concurrente.

[.center.iasc-image]
image::/public/img/guilds/guilds_2.png[]

Sin embargo, los `Guilds` aún podrían usar la interfaz `Guild::Channel` para facilitar la copia o el movimiento de objetos entre ellos. El método `transfer(object)` se propuso para permitir enviar una copia profunda del objeto al `Guild` objetivo, y `transfer_membership(object)` se propuso para permitir mover un objeto de un `Guild` a otro por completo.

[.center.iasc-image]
image::/public/img/guilds/guilds_3.png[]

[.center.iasc-image]
image::/public/img/guilds/guilds_4.png[]

Pero todo esto fue solo para objetos mutables, ya que los objetos inmutables no representan un riesgo de inconsistencia de datos. Esto es así porque una vez que se asigna un valor a los objetos inmutables, este no cambia durante la ejecución del programa, por lo que cualquier `Guild` que intente acceder a los datos de un objeto inmutable siempre recibirá el mismo valor consistente. Los objetos inmutables se podrían compartir en todos los `Guilds` para operaciones de lectura.

Los objetos inmutables en Ruby consisten en:

* Integers, `true`, `false`, `nil` (a.k.a. https://github.com/ruby/ruby/blob/d92f09a5eea009fa28cd046e9d0eb698e3d94c5c/include/ruby/internal/special_consts.h#L179[SPECIAL_CONST_P()])
* Todos los símbolos
* Strings u objetos 'frizados'. Ej: `s = "str".freeze`, donde `s` es inmutable.
* Objetos numericos: Float, Complex, Rational, big integers (https://github.com/ruby/ruby/blob/62bc4a9420fa5786d49391a713bd38b09b8db0ff/include/ruby/internal/value_type.h#L123[T_BIGNUM in internal])
* objetos como clases o modulos  (T_CLASS, T_MODULE and T_ICLASS en internal).
* Ractor y otros objetos especiales usados para sincronización

[.center.iasc-image]
image::/public/img/guilds/guilds_5.png[]

[discrete]
===== Uso propuesto de los Guilds

Koichi habla en su presentación del uso de este nuevo tipo de abstracciónfootnote:7[], y que separa en distintos casos de uso

* Caso de Uso 1: Maestro - Worker

La idea de este caso de uso es que exista un `Guild` maestro, que inicialice la ejecución, y después existan, uno o más `Guilds` que realizaran el procesamiento (workers). Este modelo se basa en delegación de tareas repetitivas o conocidas por los `Guilds` workers, y el maestro, solo se encargará de enviar por medio de un channel, el dato de entrada para ser procesado por un worker y tratar de esperar por una respuesta a continuación. El código de ejemplo fue el cálculo de fibonacci, que se muestra a continuación:

[,ruby]
----
def fib(n) ... end

g_fib = Guild.new(script: %q{
  ch = Guild.default_channel
  while n, return_ch = ch.receive
    return_ch.transfer fib(n)
  end
})

ch = Guild::Channel.new

g_fib.transfer([3, ch])

puts ch.receive
----

En el ejemplo, solo se realiza el calculo de un solo valor, aunque puede llamarse múltiples veces a `g_fib`, para que se creen nuevos `guilds`, y puedan procesar en paralelo.

[.center.iasc-image]
image::/public/img/guilds/guilds_6.png[]

* Caso de Uso 2: Pipeline

El segundo caso es el de un pipeline, en donde una serie de procesos, se separan en varios pasos, y en cada uno de estos segmentos, se trata en un `Guild` distinto. Una vez que termina el procesamiento de uno, el dato resultante se transfiere al siguiente `Guild`.

[,ruby]
----
result_ch = Guild::Channel.new

g_pipe3 = Guild.new(script: %q{
  while obj = Guild.default_channel.receive
    obj = modify_obj3(obj)
    Guild.argv[0].transfer_membership(obj)
  end
}, argv: [result_ch])

g_pipe2 = Guild.new(script: %q{
  while obj = Guild.default_channel.receive
    obj = modify_obj2(obj)
    Guild.argv[0].transfer_membership(obj)
  end
}, argv: [g_pipe3])

g_pipe1 = Guild.new(script: %q{
   while obj = Guild.default_channel.receive
   obj = modify_obj1(obj)
   Guild.argv[0].transfer_membership(obj)
   end
}, argv: [g_pipe2])

obj = SomeClass.new

g_pipe1.transfer_membership(obj)

obj = result_ch.receive
----

Aqui se muestra como la arquitectura se veria conceptualmente:

[.center.iasc-image]
image::/public/img/guilds/guilds_7.png[]

* Caso de Uso 3: Datos sensibles. Ej cuentas bancarias

Este es un caso de uso tradicional, donde tenemos datos que pueden mutar y que son sensibles. En este caso, es de alguna manera similar al caso 1, donde hay un `Guild` "maestro", que es el que posee los datos sensibles, y el estado que puede mutar. De esta manera permite aislar el estado y que solo el cambio del estado se genere con condiciones que sean controlables en un solo lugar. También permite que se puedan implementar sobre el Guild "maestro", mecanismos de seguridad y de transaccionalidad, donde se puede loggear todos los movimientos y en caso de que se tenga que volver para atrás se puede hacer, solo en un solo lugar.

[,ruby]
----
g_bank = Guild.new(script: %q{
   while account_from, account_to, amount,
     ch = Guild.default_channel.receive
     if (Bank[account_from].balance < amount)
       ch.transfer :NOPE
     else
       Bank[account_to].balance += amount
       Bank[account_from].balance -= amount
       ch.transfer :YEP
     end
  end
})
…
----

Si se observa el diagrama conceptual para esta arquitectura, se dará cuenta de que es lo mismo que el concepto que el `caso 1`, pero el único cambio clave es que los datos, recursos, etc., pertenecen únicamente al `guild` maestro.

[.center.iasc-image]
image::/public/img/guilds/guilds_8.png[]

[discrete]
==== Ractors, la implementación de Guilds

Ractors, fue lanzado como experimental en https://www.ruby-lang.org/en/news/2020/12/25/ruby-3-0-0-released/[Ruby 3.0.0], y es la implementación, por el momento mas estable de la idea conceptual de Guilds.

[.center.iasc-image]
image::/public/img/guilds/homer-grill.gif[]

La idea por atrás es la misma, un `ractor` tiene uno o más hilos, y cada uno de estos, a su vez, alberga una o más "fibers"/corutinas. y dos `ractors`, pueden ejecutarse potencialmente en paralelo, siempre y cuando el procesamiento que haya que realizar en estos sea bastante intensivo.

La idea de aislamiento de variables o datos mutables es la misma que la planteada en los `Guilds`. Un `ractor` no puede acceder a los datos de otro, a menos que se transfiera o copie el mismo, pero esto solo aplica a los datos mutables. Con respecto a las variables/datos inmutables, estos se pueden acceder sin problemas, entre los `ractors` que existan en el sistema.

La mayor diferencia viene, en cuanto a la comunicación entre los `ractors`. Estos a diferencia de los `Guilds`, se comunican por medio de simples pasos de mensajes, en vez de `channels`. La idea final es que dicho modelo sea similar al de actores. Pero lo es realmente? Esto lo veremos después. Veamos las 'ventajas'.

[discrete]
===== Ventajas??

Con respecto a las ventajas, las mismas son obvias en cuanto a lo que apuntan a resolver. Permitir la ejecución, en múltiples procesadores/cores, permite de alguna manera una mejor performance, reduciendo el tiempo promedio de ejecución de tareas que lo son, y que no generan ningún tipo de relación directa. Veamos el ejemplo mostrado en el realease de Ruby 3.0.0, donde se ejecuta el algoritmo `tak`footnote:8[https://www.amazon.com/exec/obidos/ISBN%3D0685479412/ericstreasuretroA/[Vardi, I. The Running Time of TAK. Ch. 9 in Computational Recreations in Mathematica. Redwood City, CA: Addison-Wesley, pp. 179-199, 1991.\]] footnote:9[https://archive.org/details/AcornUser052-Nov86/page/n198/mode/1up[Testing the Tak. Acorn User. pp. 197, 199.\]] secuencialmente y usando `ractors` 4 veces.

[,ruby]
----
def tarai(x, y, z) =
  x <= y ? y : tarai(tarai(x-1, y, z),
                     tarai(y-1, z, x),
                     tarai(z-1, x, y))
require 'benchmark'
Benchmark.bm do |x|
  # sequential version
  x.report('seq'){ 4.times{ tarai(14, 7, 0) } }

  # parallel version
  x.report('par'){
    4.times.map do
      Ractor.new { tarai(14, 7, 0) }
    end.each(&:take)
  }
end
----

Los resultados muestran las ventajas..

----
Benchmark result:
          user     system      total        real
seq  64.560736   0.001101  64.561837 ( 64.562194)
par  66.422010   0.015999  66.438009 ( 16.685797)
----

El codigo esta disponible también https://github.com/bossiernesto/tarai[aqui]

Esta ventaja es facil de ver, aunque lo mas interesante en realidad, es la creación de una abstracción que permita que pueda convivir de alguna manera código que soporte SMP y parte que no, sin tener que recurrir a eliminar definitivamente el GVL.

[discrete]
===== Problemas latentes

Si bien se habla que en los Ractors son thread-safe dentro de su contexto, gracias (o no..) al GGL; en realidad no son completamente `thread-safe`, ya que la interfaz que poseen todavía puede generar casos de deadlock o livelock incluso, si es que no se tiene cuidado.

Esta estructura, tiene que ser siempre usada de una manera correcta (tanto como el resto), ya que un uso poco cuidadoso, usando módulos/clases entre varios Ractorsfootnote:10[https://docs.ruby-lang.org/en/3.0.0/doc/ractor_md.html#label-Thread-safety[Ruby Lang. (2021). Ractor documentation. Thread-safety.\]], puede introducir race conditions. También otra cosa a tener en cuenta, es que el envio de mensajes entre ractors(send, yield, take, etc), es el mismo que hay entre objetos, por lo que es siempre bloqueante. Si estos se usan incorrectamente pueden resultar en `dead-locks` o `live-locks` como se menciono antes.

Por el momento, esta implementacion es experimental, por lo que pueden existir incluso bugs, tanto en el ciclo de vida, como en el manejo interno de estos en memoria (por ej. a nivel del GC de MRI aka gc.c).

[discrete]
==== Uso actual de Ractors

::: warning
Esta sección puede cambiar a lo largo del tiempo, ya que el código actual de Ractors es experimental y puede deprecarse rápidamente. Puede verse mas en la doc oficial de https://docs.ruby-lang.org/en/3.0.0/doc/ractor_md.html[ractors.md]
:::

* `+Ractor.new{expr}+` crea un nuevo Ractor y `expr` se ejecuta en paralelo en otro procesador.
* El intérprete invoca con el primer Ractor (llamado Ractor principal).
* Si el Ractor principal finaliza, todos los Ractores reciben una solicitud de finalización como hilos (si el hilo principal (el primer hilo invocado), el intérprete de Ruby envía todos los hilos en ejecución para finalizar la ejecución).
* Cada Ractor tiene 1 o más hilos.
* Los subprocesos en un Ractor comparten un bloqueo global en todo el Ractor, similar al GIL (GVL en terminología de MRI), por lo que no pueden ejecutarse en paralelo (sin liberar GVL explícitamente en el nivel C). Los hilos en diferentes ractores se ejecutan en paralelo.
* La sobrecarga de crear un Ractor es similar a la sobrecarga de la creación de un hilo usuario y el hilo de OS asociado.

[discrete]
===== Paso de mensajes

* Paso de mensaje de tipo push: `Ractor#send(obj`) y `Ractor.receive()`.
 ** El ractor remitente pasa el obj al ractor r mediante `r.send(obj)` y el ractor receptor recibe el mensaje con Ractor.receive.
 ** El remitente conoce el Ractor de destino r y el receptor no conoce al remitente (acepte todos los mensajes de cualquier ractor).
 ** El receptor tiene una cola infinita y el remitente pone en cola el mensaje. El remitente no bloquea para poner el mensaje en esta cola.
 ** Este tipo de intercambio de mensajes se emplea en muchos otros lenguajes basados ​​en actores.
* Comunicación de tipo pull: `Ractor.yield(obj)` y `Ractor#take()`.
 ** El emisor ractor declara ceder el obj por `Ractor.yield(obj)` y el receptor Ractor lo toma con r.take.
 ** El remitente no conoce un Ractor de destino y el receptor conoce el Ractor r del remitente.
 ** El remitente o el receptor se bloquearán si no hay otro lado.

[discrete]
===== Ciclo de Vida

Puede verse un resumen del ciclo de vida de un ractor en el siguiente https://github.com/ruby/ruby/blob/83a744dd8c0d6e769258b734b9f6861a22eeb554/ractor.c#L1449[diagrama]:

----
 created
   | ready to run
 ====================== inserted to vm->ractor
   v
 blocking <---+ all threads are blocking
   |          |
   v          |
 running -----+
   | all threads are terminated.
 ====================== removed from vm->ractor
   v
 terminated

 status is protected by VM lock (global state)
----

El ciclo de vida empieza con `Ractor.new` donde una vez que se registra el mismo en `+vm->ractor+`, esto sucede una vez que puede tomarse control del GVL, para proceder a la creación e inicialización de memoria del contexto. Una vez que el ractor está creado, siempre tendrá como mínimo un hilo, y en caso de que el mismo pueda ejecutarse, pasara a estado `running`. En caso de que se envíe un mensaje o se espere alguna acción se pasará a tener otro hilo planificado en primer plano del ractor, en caso de que todos los hilos se bloqueen, el estado pasa a `bloqueado`. Cuando todos los hilos han finalizado, el ractor pasa a `terminated`.

Todos los cambios de estado implican un cambio del estado del ractor, y el mismo está protegido por el GVL de la VM.
